% !BIB program = biber

\documentclass[11pt, oneside]{report}

% set up some more document options
\usepackage[utf8]{inputenc}
\usepackage[parfill]{parskip}
\usepackage[english]{babel}
\usepackage{csquotes}

\usepackage{geometry}
\geometry{letterpaper, margin = 1in, bottom = 1in}

% various packages
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{relsize}
\usepackage{microtype}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{titlesec}
\usepackage{booktabs}
\usepackage{endnotes}
\usepackage{textcomp}
\usepackage{tabularx}
\usepackage{multicol}
\usepackage{subfig}
\usepackage{lipsum}
\usepackage[table]{xcolor}
\usepackage{listingsutf8,multicol}
\usepackage{chngcntr}
\usepackage[justification=centering]{caption}
\usepackage{comment}

% font for listings
\usepackage[T1]{fontenc}
\usepackage[scaled]{beramono}
\newcommand\Small{\fontsize{8}{8.15}\selectfont}
\newcommand\Tiny{\fontsize{6}{6.1}\selectfont}
\newcommand*\LSTFont{\Small\ttfamily\SetTracking{encoding=*}{-60}\lsstyle}
\newcommand*\LSTLineNumberFont{\Tiny\ttfamily\SetTracking{encoding=*}{-60}\lsstyle}

% configure listings (for source code excerpts)
\definecolor{listinggray}{gray}{0.9}
\definecolor{listingbackground}{rgb}{0.9,0.9,0.9}
\definecolor{listingscol}{rgb}{0.6,0.6,0.6}
\lstset{
	backgroundcolor=\color{listingbackground},
	tabsize=4,
	rulecolor=\color{listingscol},
	language=c,
        basicstyle=\LSTFont,
        upquote=true,
		numbers=left,							% Line nums position
		numberstyle=\LSTLineNumberFont,			% Line-numbers fonts
		stepnumber=1,                           % Step between two line-numbers
		numbersep=5pt,                          % How far are line-numbers from code
        aboveskip={1.5\baselineskip},
        showstringspaces=true,
        extendedchars=true,
        breaklines=true,
        prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
        frame=shadowbox,
		breaklines=true,                        % Automatic line breaking?
        showtabs=true,
        showspaces=false,
        showstringspaces=false,
        identifierstyle=\ttfamily,
        keywordstyle=\color[rgb]{0,0,1},
        commentstyle=\color[rgb]{0.133,0.545,0.133},
        stringstyle=\color[rgb]{0.627,0.126,0.941},
}

% plots
\usepackage{pgfplots}
\pgfplotsset{compat=newest}

\definecolor{graph1}{rgb}{0.1, 0.1, 0.1}
\definecolor{graph2}{rgb}{0.75, 0.75, 0.75}
\pgfplotscreateplotcyclelist{triangle}{
	{graph1},
	{graph2},
}

\include{include/pie.tex}

% a command to allow text to justify and word-wrap
\newcommand*\justify{%
	\fontdimen2\font=0.4em% interword space
	\fontdimen3\font=0.2em% interword stretch
	\fontdimen4\font=0.1em% interword shrink
	\fontdimen7\font=0.1em% extra space
	\hyphenchar\font=`\-% allowing hyphenation
}

% hide the "Chapter N" text and set spacing	
\makeatletter
\def\@makechapterhead#1{%
	\vspace*{40\p@}
	{\parindent \z@ \raggedright \normalfont
		\ifnum \c@secnumdepth >\m@ne
			\par\nobreak
			\vskip 20\p@
		\fi
		\interlinepenalty\@M
		\huge \bfseries #1\par\nobreak
		\vskip 20\p@
	}
}
\makeatother

% set up glossary
\usepackage[toc, nonumberlist]{glossaries, appendix}
\makeglossaries

\include{include/glossary/terms}
\include{include/glossary/acronyms}

% bibliography
\usepackage[sorting=nty,backend=biber,style=verbose-trad1]{biblatex}

\addbibresource{include/bibliography.bib}

% begin document
\begin{document}

% title page
\begin{titlepage}
	\centering
	{\scshape\LARGE Westwood High School \par}
	\vspace{0.66cm}
	{\scshape\Large IB Extended Essay\par}
	\vspace{1.5cm}
	{\huge\bfseries What are some common 3D rendering techniques, and their impact on the visual quality and performance, that can be used to achieve photorealism?\par}
	\vspace{1.5cm}
	{\Large\itshape Tristan Seifert\par}
	\vspace{0.33cm}
	{\large Word Count: 3401\par}
	\fcolorbox{black}{red}{\Large\itshape {\color{white} \textsc{ Draft Copy }}}
	\vfill
	
	IB Candidate Number:\par
	000883-0108

	\vfill

	{\large October 27, 2015 \par}
\end{titlepage}

% abstract
{
	\renewcommand{\addtocontents}[2]{}
	\chapter*{Abstract}
}
blah

% table of contents
\tableofcontents

% introduction to CGI and the problems with photorealism
\chapter{Introduction}
\section{A Short History of 3D Graphics}
Ever since computers have been able to output graphics in any form, people have always sought to get better quality out of them. Compared to the blocky, low-resolution graphics of the 1970s, today’s incredibly realistic 3D graphics have come incredibly far. However, this incredible realism comes at a cost: developers must balance precisely the graphical quality they desire with the capabilities of available hardware.

Many techniques have been developed—most in the last decade alone—that simplify natural phenomena so that computers can efficiently approximate them for graphics. The requirements of each project are different, but this paper will look at several techniques commonly to most 3D visualizations (such as videogames,) and analyze what effect they have on the performance of the rendering pipeline, and compare the effects they have on the realism and appearance of the output.

\section{Real-time 3D Graphics}
While computers have been able to produce incredibly photorealistic 3D scenes for decades, it has only been recently that the computing capacity of \glspl{GPU} has caught up and made it possible to do so in realtime: a prime example of which are modern videogames.

To be considered realtime, graphics must be rendered at interactive \glspl{frame rate}: rates at which the human eye is unable to discern the individual frames, and they flow together into one smooth image: similarly to how a film is many different frames shown in rapid succession.

Typically, 60 \gls{fps} is used, as most displays' \glspl{refresh rate} are 60Hz---though 30\gls{fps} and 120\gls{fps} have been growing in popularity recently.

However, despite these advances in computing capacity, achieving both photorealism and interactive \glspl{frame rate}---the 'forbidden fruit' of 3D graphics---still remains an incredibly difficult task: a task which requires many clever techniques and trade-offs to 'fake' the way in which objects interact in a 3D space.

\subsection{Limiting Factors}
When rendering a scene, an immense amount of information needs to be rapidly accessed by the \gls{GPU} to actually produce an output, much of which is heavily processed by \glspl{shader} before it is even displayed. The speed at which this information can be read from memory, known as the \gls{memory bandwidth} is often a limiting factor: a problem known as memory bus saturation. Other times---especially on lower-end \glspl{GPU}---the \glspl{compute unit} are fully utilized and cannot operate any faster, causing the rest of the \gls{graphics pipeline} to stall: an unsurprising fact, considering that many effects rely on incredibly complex vector mathematics.

\section{Analyzing Improvements}
To analyze the effects of various techniques—\gls{deferred shading}, \gls{HDR}, \gls{bloom}, \gls{shadow mapping}, \gls{ambient occlusion}, and \gls{FXAA}—I developed a testbed with a flexible rendering pipeline that has features similar to those of a modern video game. It is written entirely in standards-compliant \texttt{C99} and \texttt{C++1y}.

When coupled with debuggers, static and dynamic analyzers, such as Apple's Instruments and \gls{OpenGL} Profiler, very accurate data about the impacts of these techniques on performance can be acquired, down to a breakdown of which line of code takes the longest to execute.

To maintain a constant environment, all tests will be run on the same machine: a mid-2012 MacBook Pro, featuring a 2.3GHz Intel i7, 16GB of RAM, and an NVIDIA GeForce GT 650M, with 512MB of video memory. Additionally, all tests are ran in windowed mode, at a resolution of $1024 \times 768$ pixels, 32 \gls{bpp}, using \gls{OpenGL} version 4.2.

% where each of the techniques is analyzed 
\chapter{Deferred Shading}
Traditionally, rendering pipelines calculated lighting information for every \gls{texel}, whether it would be displayed or not, wasting an immense amount of resources, even if invisible geometry is discarded early through \glspl{depth test}.

Deferred rendering performs complex lighting calculations \textit{after} all geometry has been rendered, freeing up significant resources for other tasks\footcite{gpupro-deferred}. More realistic lighting can be implemented: for example, by using a higher exponent (thus leading to smoother reflections) with the \gls{Blinn-Phong reflection model}.\footcite{ferko-deferred}

To achieve all of this, deferred shading works by rendering all texels into a \gls{G Buffer}, then running an additional shading pass to perform lighting calculations all at once.

\section{Geometry Buffer}
The geometry buffer is a collection of distinct buffers: \gls{specular} highlights (colours of sampled textures) and albedo; surface normals (used in calculating reflections) and fragment depth. Position is required for lighting calculations, but can be derived from depth via some transformations.

\begin{figure}[!htbp]
  \centering
  \subfloat[Albedo and \gls{specular}]{\includegraphics[width=0.32\textwidth]{images/lighting_gBuf_albedoSpec.png}\label{fig:f11}}
  \hfill
  \subfloat[Surface normals]{\includegraphics[width=0.32\textwidth]{images/lighting_gBuf_normals.png}\label{fig:f12}}
  \hfill
  \subfloat[Depth]{\includegraphics[width=0.32\textwidth]{images/lighting_gBuf_depth.png}\label{fig:f13}}
  \caption{Components of the G buffer in the testbed's deferred shading implementation.}
\end{figure}

Rendering of objects in the scene is performed by a simple \gls{shader}, which serves to consolidate its inputs, mixing them as appropriate, and writing them to the G buffer. While this does require a significant amount of additional video memory---particularly since the normal and depth buffers need high precision \glspl{float} to represent their values---it simplifies the lighting processing.

Information about lights, encoded as structures, is sent to a shader, which also takes the G buffer as an input. It performs the necessary calculations for each \gls{texel} and outputs it to the next stage in the rendering pipeline.

\section{Lighting Calculations}
Thanks to the flexibility of performing all lighting at once, many different types of lighting can be implemented. In the testbed, four types of lighting are supported: ambient light, directional lights, point lights, and spotlights. Each of these lights has an associated \gls{specular} and \gls{diffuse} colour.

\subsection{Ambient Light}
Ambient light is an average of all non-specific light sources in a scene, with a fixed colour, affecting every \gls{texel} equally.

\subsection{Directional Light}
Directional lights are an approximation of light sources that are infinitely far away, modeled as a series of parallel light rays. They have a diffuse and specular colour, and a direction that indicates which way the light rays will be cast. Any \gls{texel} that intersects with a light ray from a directional light will be affected by it.

Directional lights are the only lights that will cause shadows to be cast.

\subsection{Point Light}
Point lights are similar to directional lights, except they have a position instead of a direction. Light rays are cast in all directions from this center point, and like directional lights, any \gls{texel} in their path will be affected by it. Instead of a constant effect, however, point lights' influence gets weaker the farther the \gls{texel} is from the light source.\footcite{pointlight-attenuate}	

This attenuation is defined by a constant ($K_c$), a linear ($K_l$) and a quadratic ($K_q$) term, as well as the distance from the light ($d$) and unattenuated intensity ($I$): \begin{equation} F_{att} = \frac{I}{K_c + K_l * d + K_q * d^2} \end{equation}

To get the effect a point light has on a \gls{texel}, its specular and diffuse colours are multiplied by $F_{att}$.

\subsection{Spotlight}
Spotlights are special cases of point lights, with a direction in addition to a position, as well as a radius. They cast light rays as a cone with a given radius, and illuminate everything within. Toward the edge of the circle, the intensity of the light begins to rapidly fall off.

\section{End Result}
When combining all of these lighting types, a good approximation of the real environment can be created.

\begin{figure}[!htbp]
   \centering
   \includegraphics[width=0.74\textwidth]{images/lighting_out.png}
   \caption{Output of the lighting stage, without gamma compensation, with values > \texttt{1.0} clipped. A \gls{skybox} was rendered in areas where lighting calculations produced no output.}
   \label{fig:f14}
\end{figure}

But what about particularly bright lights, or really dark ones? The standard approach to rendering them will cause \glspl{texel} illuminated by them to appear as solid bright or dark areas, losing most detail. \gls{HDR} solves that problem, by having the lighting pass output an intermediate, unbounded representation of light intensity.\footcite{trebilco-deferred}

A downside of deferred shading is that objects that previously affected light in unique ways are more difficult to implement, since all lighting calculations are in the same shader. Additionally, a significant amount of memory is consumed by the \gls{G Buffer}, so it is not uncommon to reuse components of the \gls{G Buffer} for other purposes.

\subsection{Performance Impact}
By far, deferred shading consumes a significant piece of the frame's processing time. Approximately 9.6\% of the frame processing time goes towards deferred shading. However, compared to the tremendous savings over per-pixel shading, this is still a massive reduction in processing time.

\begin{table}[!htbp]	
	\centering
	\footnotesize
	
	\definecolor{HeaderGray}{gray}{0.74}
		
	\begin{tabularx}{0.88\textwidth}{| r | c | c | >{\tt}X |}	
		\hline
		\rowcolor{HeaderGray}
		\multicolumn{2}{|c|}{Running Time} & Self (ms) & \multicolumn{1}{ c |}{Symbol Name} \\
		\hline
		574.0ms & 9.6\% & 3.0 & {gfx::SceneLighting::render()} \\
		\hline

		356.0ms & 5.9\% & 2.0 & {gfx::SceneLighting::sendLightsToShader()} \\
		89.0ms & 1.4\% & 1.0 & {gl::glDrawArrays(gl::GLenum, int, int)} \\ 
		60.0ms & 1.0\% & 0.0 & {gfx::SceneLighting::renderSkybox()} \\
		20.0ms & 0.3\% & 2.0 & {glm::tmat4x4<float>::inverse} \\[1ex]
		
		13.0ms & 0.2\% & 0.0 & {gfx::ShaderProgram::setUniform1f(std::string, float)} \\
		12.0ms & 0.2\% & 1.0 & {gfx::ShaderProgram::bind()} \\
		5.0ms & 0.0\% & 1.0 & {gfx::Texture2D::bind()} \\
		4.0ms & 0.0\% & 0.0 & {gfx::Texture2D::unbind()} \\[1ex]
		
		3.0ms & 0.0\% & 0.0 & {gfx::ShaderProgram::setUniformVec(std::string, glm::tvec3<float>)} \\
		2.0ms & 0.0\% & 0.0 & <Unknown Address> \\
		2.0ms & 0.0\% & 0.0 & {gfx::ShaderProgram::setUniformMatrix(std::string, glm::tmat4x4<float>)} \\
		1.0ms & 0.0\% & 0.0 & {gfx::VertexArray::unbind()} \\
		\hline
	\end{tabularx}
	
	\caption{Stack trace showing computational impact of deferred shading.}
	\label{tab:booktabs}
\end{table}

Before deferred shading, lighting was calculated for each \gls{texel}. Average frame rendering times sat at approximately 6.3mS, with rendering and lighting consuming a whopping 93.7\% of that time---the majority of which was spent performing complex lighting calculations over texels that would not even be rendered. Implementing deferred shading single-handedly brought the per-frame rendering time down to approximately 2.9mS.

Of the processing overhead incurred by deferred shading, approximately two thirds go towards sending lighting information (such as position, coefficients, colours, etc.) to the lighting shader. Another 10\% go towards rendering a skybox.

As far as memory use goes, deferred shading is relatively resource hungry. Because of the amount of data that is needed for lighting, the \gls{G Buffer} becomes quite large. Three buffers need to be allocated, at full screen resolution---the albedo and specular buffer, a 32 \gls{bpp} integer buffer; the surface normals, a 64 \gls{bpp} floating point buffer; and the depth buffer, a combined depth and stencil floating point format, requiring 32 \gls{bpp}.

An additional 14MB of memory are required for the \gls{G Buffer}. However, all components of the buffer can be reused after the lighting pass for other steps of the rendering pipeline to reduce the overall memory footprint.

\chapter{High Dynamic Range (HDR) and Bloom}
One of the biggest problems of computer graphics has traditionally been to approach the dynamic range of the human eye, even though display devices have a limited colour palette they can display. Particularly, the human eye is much better at recovering detail from very bright and very dark areas than a computer display can show, so a large range of brightness values must somehow be mapped onto the handful of nonlinear brightness values displayed by computer monitors: this is exactly what \gls{HDR} does.

Additionally, due to optical imperfections in lenses (the eye is really one big lens) there often appears bleeding of light from very bright to darker areas. By applying \gls{bloom}, the brightness of a light source can be exaggerated and shown more clearly.

\section{Producing HDR Output}
The deferred shading pass outputs colour values into a \gls{floating point} buffer, allowing for a nearly infinite amount of brightness values to be expressed. The conversion between HDR values and \gls{RGB} values is relatively straightforward, and is defined by a function in a \gls{shader}; also known as \gls{tone mapping}. These values are also adjusted to match a certain \gls{white point}\footcite{hdr}.

\begin{figure}[!htbp]
  \centering
  \subfloat[Before]{\includegraphics[width=0.49\textwidth]{images/lighting_out.png}\label{fig:f21}}
  \hfill
  \subfloat[After]{\includegraphics[width=0.49\textwidth]{images/bloom_hdr_out.png}\label{fig:f22}}
  \caption{Before and after \gls{tone mapping}, gamma and white point adjustments.}
\end{figure}

In addition to a particular \gls{tone mapping} algorithm, the sensitivity of \gls{HDR} can easily be adjusted via an exposure parameter. This parameter serves as a constant multiplier for the \gls{HDR} input colours before \gls{tone mapping}, and affects the overall brightness of the image: similarly to how changing the exposure settings on a photographic camera will affect the brightness of the photograph.

\begin{figure}[!htbp]
  \centering
  \subfloat[-3]{\includegraphics[width=0.19\textwidth]{images/exposure/EV_-3.jpg}\label{fig:f23}}
  \hfill
  \subfloat[-1.5]{\includegraphics[width=0.19\textwidth]{images/exposure/EV_-1_5.jpg}\label{fig:f24}}
  \hfill
  \subfloat[0]{\includegraphics[width=0.19\textwidth]{images/exposure/EV_0.jpg}\label{fig:f25}}
  \hfill
  \subfloat[1.5]{\includegraphics[width=0.19\textwidth]{images/exposure/EV_1_5.jpg}\label{fig:f26}}
  \hfill
  \subfloat[3]{\includegraphics[width=0.19\textwidth]{images/exposure/EV_3.jpg}\label{fig:f27}}
  \caption{Effects of varying exposure values (EV) on a photograph.}
\end{figure}

Overall, HDR can produce a great improvement in visual quality with little additional work. An extra stage of shader processing before output adds minimal overhead, and no additional memory is needed, if a buffer from a previous stage in the rendering pipeline is reused.

Various additional effects can be achieved simply by varying the exposure value: for example, a higher exposure value could be used for night-time scenes, and a lower one for day-time scenes. Perhaps even automatic exposure adjustment, where the overall brightness is analyzed, and exposure is slowly changed to maintain a baseline level of brightness, similar to how the human eye functions.

\section{Bloom}
Blooming simulates the glow that occurs around extremely bright light sources. In conjunction with \gls{HDR}, it is incredibly easy to implement, with little additional overhead.

\begin{figure}[!htbp]
  \centering
  \subfloat[Before]{\includegraphics[width=0.49\textwidth]{images/bloom_bright_in.png}\label{fig:f28}}
  \hfill
  \subfloat[After]{\includegraphics[width=0.49\textwidth]{images/bloom_pass4.png}\label{fig:f29}}
  \caption{Bright input fragments, before and after application of the Gaussian blur.}
\end{figure}

All fragments that are considered bright---a combined brightness of \texttt{1.0} or above---are copied into an additional buffer. This buffer is half the size as the output screen, saving memory and processing time. A second buffer of identical size is allocated. This buffer is then blurred through several iterations of a Gaussian blur until an adequate blur has been achieved.

The Gaussian blur itself consists of a $13 \times 13$ blur kernel, which is approximated by sampling the texture seven times for each \gls{texel}, using bilinear interpolation to get more samples. The blur itself has been decomposed into separate horizontal and vertical components for performance reasons, and is run over a set of two buffers---the original 'bright fragment' input buffer, and the eventual 'output' buffer---a predetermined number of times.Once blurring has been completed, the output buffer is sampled in the \gls{HDR} output shader, multiplied by a coefficient (this determines the strength and effect of the blur on the rest of the scene,) then added to the \gls{HDR} colour.

\section{End Result}
By combining both \gls{HDR} and blooming, the lighting in a scene already appears much more realistic, solving the issue of washed out highlights and details that disappear into the shadows. These two render passes require little in the way of additional memory, and their \gls{shader} programs are deceptively simple. Additionally, the \gls{HDR} pass serves as a place for gamma correction to take place. Textures are stored as sRGB, and \gls{OpenGL}'s built-in conversion is disabled. This way, the user can configure the gamma of the application to match their monitor most closely, instead of relying on a hard-coded value in a graphics driver.

\subsection{Performance Impact}
When analyzing the testbed's performance with \gls{HDR} and blooming enabled, the relatively insignificant additional overhead incurred by the technique immediately becomes clear.

\begin{table}[!htbp]	
	\centering
	\footnotesize
	
	\definecolor{HeaderGray}{gray}{0.74}
	\definecolor{Header2Gray}{gray}{0.95}
		
	\begin{tabularx}{0.88\textwidth}{| r | c | c | >{\tt}X |}	
		\hline
		\rowcolor{HeaderGray}
		\multicolumn{2}{|c|}{Running Time} & Self (ms) & \multicolumn{1}{ c |}{Symbol Name} \\
		
		\hline
		\rowcolor{Header2Gray}
		\multicolumn{4}{|c|}{\textbf{HDR}} \\
		\hline
		103.0ms & 1.7\% & 0.0 & {gfx::HDRRenderer::render()} \\
		\hline
		
		92.0ms & 1.5\% & 0.0 & {gl::glDrawArrays(gl::GLenum, int, int)} \\
		5.0ms & 0.0\% & 0.0 & {gfx::ShaderProgram::bind()} \\
		3.0ms & 0.0\% & 0.0 & {gfx::VertexArray::bind()} \\
		2.0ms & 0.0\% & 0.0 & {gfx::Texture2D::bind()} \\
		
		\hline
		\rowcolor{Header2Gray}
		\multicolumn{4}{|c|}{\textbf{Bloom}} \\
		\hline
		127.0ms & 2.1\% & 0.0 & {gfx::BloomRenderer::render()} \\
		\hline
		
		103.0ms & 1.7\% & 0.0 & {gl::glDrawArrays(gl::GLenum, int, int)} \\
		10.0ms & 0.1\% & 1.0 & {gfx::ShaderProgram::bind()} \\
		10.0ms & 0.1\% & 0.0 & {gfx::ShaderProgram::setUniform1i(std::string, int)} \\
		2.0ms & 0.0\% & 0.0 & {gfx::ShaderProgram::setUniform1f(std::string, float)} \\[1ex]
		
		2.0ms & 0.0\% & 0.0 & {gfx::ShaderProgram::setUniformVec(std::string, glm::tvec3<float>)} \\


		\hline
	\end{tabularx}
	
	\caption{Stack trace showing computational impact of HDR and blooming.}
	\label{tab:booktabs}
\end{table}

After optimizing the \gls{HDR} code to reduce \glspl{pipeline stall}, on average, 1.7\% of a frame's processing time was taken up by the blurring of highlights (for blooming) and the combination and \gls{tone mapping} of the final output.

In addition, 6.2MB of video memory were needed for buffers. The two quarter resolution buffers for blooming are 48 \gls{bpp} floating point buffers without alpha components, while the input buffer to the HDR process is a 64 \gls{bpp} floating point buffer.

Considering the improvement in visual quality that a properly implemented \gls{HDR} approach can give, the additional performance overhead is almost negligible. However, the difficulty lies in determining and implementing a good \gls{tone mapping} algorithm, that gives an output that looks realistic---not too saturated, but not too bland, either.

Furthermore, a topic of much discussion in the CGI community is blooming. It is extremely difficult to come up with a bloom threshold that is appropriate for every environment that may need to be rendered.

\chapter{Fast Approximate Antialiasing (FXAA)}
Due to the limited resolution of textures and buffers, as well as the multitude of transformations applied to geometric primitives, it is extremely common for an unprocessed output to exhibit heavy \gls{aliasing}. Most commonly, it will take the form of jagged edges, or strange transitions between colours.

In the past, aliasing was combatted by rendering the entire scene at a much higher resolution---often 2x or 4x larger than the screen---then simply downscaling it, creating a primitive form of supersampling. Later on, similar techniques were applied to \glspl{shader}, when they sampled textures, improving performance somewhat; also known as MSAA. Supersampling works in a similar manner.

What all of these antialiasing algorithms have in common is that they are very computationally expensive. They can double or quadruple the rendering time, while yielding a minimal benefit.

\section{Implementation}
Processing the output with \gls{FXAA} is straightforward. A buffer is created, into which the output of all previous stages of the rendering pipeline is stored, instead of going to the window framebuffer. This buffer is then given as an input to the \gls{FXAA} \gls{shader} program, which samples it, detects edges, smoothes them, and outputs a final antialiased output to the window framebuffer\footcite{nvidia-fxaa}.

\begin{figure}[!htbp]
  \centering
  \subfloat[With FXAA]{\includegraphics[width=0.49\textwidth]{images/fxaa_out@8x.png}\label{fig:f31}}
  \hfill
  \subfloat[Without FXAA]{\includegraphics[width=0.49\textwidth]{images/bloom_hdr_out@8x.png}\label{fig:f32}}
  \caption{A crop from the final output, with and without FXAA. Note the rough edges on on (b).}
\end{figure}

Because \gls{FXAA} is implemented in a shader\footnote{Example implementation from NVIDIA, Version 3.11 by Timothy Lottes}, rather than in hardware, its behavior (such as edge detection sensitivity, smoothing algorithm and sharpness, etc.) can be adjusted on-the-fly. 

\section{End Result}
By utilizing a new algorithm to approximate antialiasing instead of wasting precious computational resources and \gls{memory bandwidth} on traditional algorithms, immense performance gains can be made. In most cases, the quality of \gls{FXAA} is comparable to that of more traditional algorithms: and most of the time, the precise nature of the antialiasing algorithm makes little difference to the user of the program.

\subsection{Performance Impact}
Implementing \gls{FXAA} improves the quality of the output significantly, by removing \gls{aliasing} artifacts, with little impact on the performance of the rendering pipeline.

\begin{table}[!htbp]	
	\centering
	\footnotesize
	
	\definecolor{HeaderGray}{gray}{0.74}
		
	\begin{tabularx}{0.88\textwidth}{| r | c | c | >{\tt}X |}	
		\hline
		\rowcolor{HeaderGray}
		\multicolumn{2}{|c|}{Running Time} & Self (ms) & \multicolumn{1}{ c |}{Symbol Name} \\
		\hline
		127.0ms & 2.1\% & 0.0 & {gfx::FXAARenderer::render()} \\
		\hline
		
		101.0ms & 1.6\% & 0.0 & {gl::glDrawArrays(gl::GLenum, int, int)} \\
		10.0ms & 0.1\% & 2.0 & {gfx::ShaderProgram::setUniform1f(std::string, float)} \\
		10.0ms & 0.1\% & 0.0 & {gfx::ShaderProgram::setUniform1i(std::string, int)} \\
		5.0ms & 0.0\% & 0.0 & {gfx::ShaderProgram::bind()} \\[1ex]
		
		1.0ms & 0.0\% & 0.0 & {gfx::Texture2D::bind()} \\
		\hline
	\end{tabularx}
	
	\caption{Stack trace showing computational impact of deferred shading.}
	\label{tab:booktabs}
\end{table}

On average, running the \gls{FXAA} pass, using the highest 'low dither' preset specified by the shader, 2.1\% of  processing time is required to execute the \gls{FXAA} process each frame. The majority of this time is spent in the \gls{OpenGL} library, waiting for the GPU to be ready to accept a command, so there is room for further optimization.

In addition, another colour buffer is needed, increasing memory overhead by approximately 4MB. (A simple 24 \gls{bpp} buffer without alpha will suffice for this application, since all \gls{HDR} processing will have already been done on the more complex buffers.)

For the improvement in visual quality---in particular, when using large output displays, and the low impact on performance---the impact of implementing \gls{FXAA} is basically nil.

\chapter{Overall Performance}
To determine the overall effect on performance of the aforementioned rendering techniques, Apple's Instruments software was used to capture stack traces, and combining those with timing information within the testbed itself.

\begin{table}[!htbp]
	\centering
	\footnotesize
	
	\definecolor{HeaderGray}{gray}{0.74}
		
	\begin{tabularx}{0.88\textwidth}{| r | c | c | >{\tt}X |}	
		\hline
		\rowcolor{HeaderGray}
		\multicolumn{2}{|c|}{Running Time} & Self (ms) & \multicolumn{1}{ c |}{Symbol Name} \\
		\hline
		5956.0ms & 100.0\% & 3.0 & {gfx::StandardRenderer::render()} \\
		4021.0ms & 67.5\% & 5.0 & {gfx::SceneRenderer::render()} \\
		574.0ms & 9.6\% & 3.0 & {gfx::SceneLighting::render()} \\
		531.0ms & 8.9\% & 0.0 & {gfx::BloomRenderer::beforeRender()} \\[1ex]
		205.0ms & 3.4\% & 0.0 & {gfx::SceneRenderer::beforeRender()} \\
		127.0ms & 2.1\% & 0.0 & {gfx::BloomRenderer::render()} \\
		127.0ms & 2.1\% & 0.0 & {gfx::FXAARenderer::render()} \\
		103.0ms & 1.7\% & 0.0 & {gfx::HDRRenderer::render()} \\[1ex]
		96.0ms & 1.6\% & 0.0 & {gfx::SceneLighting::beforeRender()} \\
		57.0ms & 0.9\% & 0.0 & {gfx::SceneRenderer::renderNormally()} \\
		43.0ms & 0.7\% & 1.0 & {gfx::SceneLighting::bindGBuffer()} \\
		19.0ms & 0.3\% & 0.0 & {gfx::LevelCamera::updateViewMatrix()} \\[1ex]
		18.0ms & 0.3\% & 0.0 & <Unknown Address> \\
		8.0ms & 0.1\% & 0.0 & {gfx::HDRRenderer::bindHDRBuffer()} \\
		3.0ms & 0.0\% & 0.0 & {gfx::BloomRenderer::bindBloomBuffer()} \\
		3.0ms & 0.0\% & 1.0 & {gfx::FXAARenderer::beforeRender()} \\[1ex]
		2.0ms & 0.0\% & 0.0 & {gfx::FrameBuffer::unbindRW()} \\
		2.0ms & 0.0\% & 0.0 & {gfx::HDRRenderer::beforeRender()} \\
		2.0ms & 0.0\% & 0.0 & {gfx::LevelCamera::getViewMatrix()} \\
		1.0ms & 0.0\% & 1.0 & {glm::detail::tmat4x4<float>::tmat4x4()} \\[1ex]
		1.0ms & 0.0\% & 0.0 & {gfx::LevelCamera::getCameraLookAt()} \\
		1.0ms & 0.0\% & 0.0 & {gfx::SceneLighting::setFXAA(gfx::FXAARenderer*)} \\
		1.0ms & 0.0\% & 0.0 & {gfx::LevelCamera::getCameraPosition()} \\
		1.0ms & 0.0\% & 0.0 & {gfx::SceneRenderer::afterRender()} \\[1ex]
		1.0ms & 0.0\% & 0.0 & {gfx::FXAARenderer::bindFXAABuffer()} \\
		1.0ms & 0.0\% & 0.0 & {gfx::SceneLighting::afterRender()} \\
		\hline
	\end{tabularx}
	
	\caption{Stack trace showing each step of the rendering pipeline, after running it for 60 seconds.}
	\label{tab:booktabs}
\end{table}

The implementation of these techniques does indeed affect the quality of the output in a positive way. Deferred shading allows for many more lights, giving a more realistic model of how light interacts with objects in the real world. \gls{HDR} and blooming more accurately model the way in which the human eye perceives light, matching its dynamic range, and emulating some of its imperfections. FXAA smoothes the final output, getting rid of unpleasant rendering artifacts without the excessive overhead of 'real' antialiasing.

However, these gains in appearance are not entirely free. While deferred shading reduces processing time required for each \gls{texel} significantly, it requires a significant amount of memory to store the additional data required to later render the lighting effects.

HDR and FXAA require additional memory as well, but provide an incredible increase in the quality of the output with little additional processing time required.

While these basic techniques by themselves do not magically create photorealistic outputs, they are significant steps towards allowing for much more complex shaders, and other processing techniques, that allow true photorealism. For example, dynamic reflections and shadows could be used to enhance the appearance of objects. More complex and detailed textures and normal maps could allow rendered objects to have more detail than the mesh used to render them really does.

Overall, these techniques do contribute quite significantly to the appearance and quality of the final output. While they by themselves do not achieve photorealism, they definitely serve as important foundations for achieving photorealism.

\begingroup
	\printbibliography[
		heading=bibintoc,
		title={Bibliography}
	]
\endgroup

\printglossaries

\end{document}